{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INGESTÃO DE DADOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_paths = {\n",
    "    'admissions': 'rawcsvs/ADMISSIONS.csv',\n",
    "    'microbiology_events': 'rawcsvs/MICROBIOLOGYEVENTS.csv',\n",
    "    'prescriptions': 'rawcsvs/PRESCRIPTIONS.csv',\n",
    "    'labevents': 'rawcsvs/LABEVENTS.csv',\n",
    "    'diagnoses_icd': 'rawcsvs/DIAGNOSES_ICD.csv',\n",
    "    'patients': 'rawcsvs/PATIENTS.csv',\n",
    "    'transl-labitems': 'rawcsvs/D_LABITEMS.csv',\n",
    "    'transl-diag': 'rawcsvs/D_ICD_DIAGNOSES.csv'\n",
    "}\n",
    "\n",
    "cols_to_use = {\n",
    "    'admissions': ['subject_id','admittime','ethnicity', 'admission_type'],\n",
    "    'microbiology_events': ['row_id', 'subject_id',  'chartdate', 'charttime', 'spec_itemid', 'spec_type_desc', \n",
    "                            'org_itemid', 'org_name', 'isolate_num', 'ab_itemid', 'ab_name', 'dilution_text', \n",
    "                            'dilution_comparison', 'dilution_value', 'interpretation'],\n",
    "    'prescriptions': ['subject_id', \"hadm_id\", 'drug', 'enddate'],\n",
    "    'labevents': ['subject_id', 'itemid', 'valuenum', 'valueuom', 'flag'],\n",
    "    'diagnoses_icd': ['subject_id', 'icd9_code'], #gotta work on this one, adding all codes to one line in the array\n",
    "    'transl-labitems': ['itemid', 'label'], # use this in conjunction with labevents to understando wtf if happening\n",
    "    'patients': ['subject_id', 'gender'],\n",
    "    'transl-diag': ['icd9_code', 'short_title', 'long_title']\n",
    "}\n",
    "\n",
    "files = {}\n",
    "for file_path in file_paths:\n",
    "    files[file_path] = pd.read_csv(file_paths[file_path], usecols=cols_to_use[file_path])\n",
    "    \n",
    "for file_path, file in files.items(): \n",
    "    if  not file_path.startswith('transl'):\n",
    "        file.dropna(inplace=True, subset=['subject_id'])\n",
    "        file.drop_duplicates(inplace=True)  \n",
    "        file_name = os.path.basename(file_path)\n",
    "        file.to_csv(f'cleanedcsv/{file_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANEIRA PARA JUNTAR TODOS OS DADOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Isso esta feito para essas duas tabelas\n",
    "o modo nao mudou, precisa mudar as tabelas importadas, as colunas pivoteadas, e o valor de value, dependendo do que \n",
    "precisa ser pivoteado\n",
    "Agradeco Pedro por me dar a idea de pivotear as tabelas\n",
    "'''\n",
    "import pandas as pd\n",
    "mergedata = pd.read_csv('mergedcsv/admin-diag-lab-micro.csv')\n",
    "diagnoses = pd.read_csv('cleanedcsv/prescriptions.csv')\n",
    "\n",
    "\n",
    "#inverter a tabela de diagnósticos para ter uma linha por paciente\n",
    "\n",
    "diaginv = diagnoses.assign(value=1).pivot_table(\n",
    "    index='subject_id', \n",
    "    columns='drug', \n",
    "    values='value', \n",
    "    fill_value=0\n",
    ").reset_index()    # Reset the index to make `subject_id` a column\n",
    "\n",
    "diaginv.fillna(0, inplace=True)\n",
    "\n",
    "# Now proceed with the merge\n",
    "mergedata = mergedata.merge(diaginv, on='subject_id', how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRADUCAO DE CODIGOS PARA TEXTOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#Need to convert the icd9_codes into text\n",
    "def tryconvertint(possibleint):\n",
    "    try:\n",
    "        x = int(possibleint)\n",
    "        return x\n",
    "    except ValueError:\n",
    "        return possibleint \n",
    "\n",
    "#first, I will get a representation of all the possible codes and their respective values\n",
    "unique_diag_codes = pd.read_csv(os.path.join('rawcsvs', 'D_ICD_DIAGNOSES.csv')).filter(['icd9_code', 'short_title']).drop_duplicates()\n",
    "unique_labitem_codes = pd.read_csv(os.path.join('rawcsvs', 'D_LABITEMS.csv')).filter(['itemid', 'label']).drop_duplicates()\n",
    "\n",
    "#second, I will iterate through each column name and replace it with the title and/or label\n",
    "allthedata = pd.read_csv(os.path.join('mergedcsv', 'admin-diag-lab-micro-pat-prescrip.csv'))\n",
    "\n",
    "new_columns = []\n",
    "\n",
    "for column in allthedata.columns:\n",
    "    colint = tryconvertint(column)\n",
    "    if colint == 50800:\n",
    "        x = unique_labitem_codes['itemid'].values\n",
    "        pass\n",
    "\n",
    "    # Check if the column is in the 'icd9_code' of unique_diag_codes\n",
    "    if column in unique_diag_codes['icd9_code'].values:\n",
    "        # Map it to 'short_title'\n",
    "        new_columns.append(unique_diag_codes.loc[unique_diag_codes['icd9_code'] == column, 'short_title'].values[0])\n",
    "\n",
    "    # Check if the column is in the 'itemid' of unique_labitem_codes\n",
    "    elif colint in unique_labitem_codes['itemid'].values:\n",
    "        # Map it to 'label'\n",
    "        new_columns.append(unique_labitem_codes.loc[unique_labitem_codes['itemid'] == colint, 'label'].values[0])\n",
    "\n",
    "    # If not found, retain the original column name\n",
    "    else:\n",
    "        new_columns.append(column)\n",
    "\n",
    "allthedata.columns = new_columns\n",
    "allthedata.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACAO DE DADOS IMPORTANTES A BUSCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "#supunhetemos que tenhamos uma busca\n",
    "ab_name = 'vancomycin'  # Define a default value for ab_name\n",
    "search = ab_name if ab_name else 'vancomycin'\n",
    "#precisamos listar todas as doencas em que o medicamento foi usado\n",
    "#para facilitar a busca, precisamos calcular o medicamento mais provavel que foi escrito\n",
    "all_drugs = files['microbiology_events']['ab_name'].dropna().unique()\n",
    "\n",
    "closest_drug = None\t\n",
    "for drug in all_drugs:\n",
    "    dist = Levenshtein.distance(search, drug)\n",
    "    if closest_drug is None or dist < closest_drug[1]:\n",
    "        closest_drug = (drug, dist)\n",
    "\n",
    "#agora que temos o medicamento mais provavel, podemos listar as resistencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coletando os dados de resistencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "#need to sort he diseases\n",
    "closest_drug = files['microbiology_events']['ab_name'].mode()[0]\n",
    "diseases = files['microbiology_events'][files['microbiology_events']['ab_name'] == closest_drug[0]]['org_name'].unique()\n",
    "\n",
    "\n",
    "\n",
    "dis_res_count = {}\n",
    "for disease in diseases:\n",
    "    disease_res = files['microbiology_events'][\n",
    "        (files['microbiology_events']['ab_name'] == closest_drug[0]) & \n",
    "        (files['microbiology_events']['org_name'] == disease)\n",
    "    ]['interpretation']\n",
    "    \n",
    "    # Initialize counts for 'R', 'I', 'S'\n",
    "    counts = {'R': 0, 'I': 0, 'S': 0}\n",
    "    \n",
    "    counts.update(disease_res.value_counts().to_dict())\n",
    "    \n",
    "    dis_res_count[disease] = counts\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FODASSE O MODELO PREDITIVO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, jsonify, redirect, url_for, session\n",
    "import Levenshtein\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'VAI SE FUDER FIGA' #perdao bita cabrita\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def home():\n",
    "    if request.method == 'GET':\n",
    "        return render_template('busca.html')\n",
    "    elif request.method == 'POST':\n",
    "        ab_name = request.form.get('ab_name')\n",
    "\n",
    "        def search(term):\n",
    "            all_drugs = files['microbiology_events']['ab_name'].dropna().unique()\n",
    "\n",
    "            closest_drug = None    \n",
    "            for drug in all_drugs:\n",
    "                dist = Levenshtein.distance(term, drug)\n",
    "                if closest_drug is None or dist < closest_drug[1]:\n",
    "                    closest_drug = (drug, dist)\n",
    "            return closest_drug\n",
    "        \n",
    "\n",
    "        if ab_name:\n",
    "            droga = search(ab_name)\n",
    "            session['droga'] = droga[0]  # Armazena apenas o nome da droga na sessão\n",
    "            return redirect(url_for('resposta'))\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Nome do antibiótico não informado\"}), 400\n",
    "\n",
    "# Rota para a página secundaria (resposta)\n",
    "\n",
    "@app.route('/resposta')\n",
    "\n",
    "def resposta():\n",
    "    closest_drug = session.get('droga')  # Recupera a droga da sessão\n",
    "\n",
    "    # Verifica se o medicamento foi encontrado\n",
    "    if closest_drug:\n",
    "        # Chama a função que calcula as contagens de resistência\n",
    "        resistencias = dis_res_count(closest_drug)\n",
    "    else:\n",
    "        resistencias = {}\n",
    "\n",
    "    # Renderiza o template com os dados de resistência\n",
    "    return render_template('resposta.html', closest_drug=closest_drug, resistencias=resistencias)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run() \n",
    "\n",
    "\n",
    "def dis_res_count(closest_drug):\n",
    "    # Filtra as doenças baseadas no medicamento mais próximo\n",
    "    diseases = files['microbiology_events'][files['microbiology_events']['ab_name'] == closest_drug]['org_name'].unique()\n",
    "    \n",
    "    # Dicionário para armazenar a contagem de resistência por doença\n",
    "    dis_res_count = {}\n",
    "\n",
    "    # Itera sobre cada doença e conta as interpretações 'R', 'I', 'S'\n",
    "    for disease in diseases:\n",
    "        disease_res = files['microbiology_events'][\n",
    "            (files['microbiology_events']['ab_name'] == closest_drug) & \n",
    "            (files['microbiology_events']['org_name'] == disease)\n",
    "        ]['interpretation']\n",
    "        \n",
    "        # Inicializa a contagem de 'R', 'I', 'S'\n",
    "        counts = {'R': 0, 'I': 0, 'S': 0}\n",
    "        \n",
    "        # Atualiza as contagens com base nas interpretações\n",
    "        counts.update(disease_res.value_counts().to_dict())\n",
    "        \n",
    "        # Armazena a contagem da doença atual\n",
    "        dis_res_count[disease] = counts\n",
    "\n",
    "    return dis_res_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o dataset para o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "patients = pd.read_csv(os.path.join('rawcsvs', 'PATIENTS.csv'))\n",
    "admissions = pd.read_csv(os.path.join('rawcsvs', 'ADMISSIONS.csv'))\n",
    "microbiology = pd.read_csv(os.path.join('rawcsvs', 'MICROBIOLOGYEVENTS.csv'))\n",
    "\n",
    "\n",
    "# Merge the patients and admissions dataframes  \n",
    "new_data = (admissions\n",
    "            .filter(['subject_id', 'admission_type', 'ethnicity', 'diagnosis', 'hospital_expire_flag', 'insurance', 'religion', 'marital_status'])\n",
    "            #.drop(admissions[admissions['hospital_expire_flag'] == 1].index)\n",
    "            .merge(patients, on='subject_id', how='left')\n",
    "            )\n",
    "#merge the microbiology data\n",
    "new_data = (\n",
    "    microbiology\n",
    "    .filter(['subject_id', 'ab_name', 'interpretation'])\n",
    "    # One hot encoding the interpretation\n",
    "    .assign(value=(microbiology['interpretation'] == 'R').astype(int))\n",
    "    .reset_index(drop=True)\n",
    "    .merge(new_data, on='subject_id', how='left')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "aux1 = ( # one hot enconding e passando para formato largo os diagnósticos\n",
    "    new_data\n",
    "    .filter(['subject_id', 'diagnosis'])\n",
    "    .assign(value=1)\n",
    "    .pivot_table(index='subject_id', columns='diagnosis', values='value', fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "aux2 = (\n",
    "    new_data\n",
    "    .groupby('subject_id')\n",
    "    .agg({\n",
    "        'insurance': 'first',\n",
    "        'religion': 'first',\n",
    "        'marital_status': 'first',\n",
    "        'ethnicity': 'first',\n",
    "        'gender': 'first',\n",
    "        'ab_name': 'first',\n",
    "        'interpretation': 'first'\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "filtered_data = aux1.merge(aux2, on='subject_id', how='left')\n",
    "filtered_data.to_csv('improving.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering (Fuck data science)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Assuming your DataFrame is called 'df'\n",
    "df = pd.read_csv('improving.csv', sep=',')\n",
    "\n",
    "# Step 1: Identify non-disease columns\n",
    "non_disease_columns = ['subject_id', 'insurance', 'religion', 'marital_status', 'ethnicity', 'gender', 'ab_name', 'interpretation'] \n",
    "\n",
    "# Identify disease columns by excluding non-disease columns\n",
    "disease_columns = [col for col in df.columns if col not in non_disease_columns]\n",
    "\n",
    "# Step 2: Create a mapping from each disease to disease types\n",
    "# Define your disease types and map diseases to them\n",
    "disease_type_mapping = {\n",
    "    'Cardiovascular': ['ACUTE PULMONARY EMBOLISM', 'CONGESTIVE HEART FAILURE', 'CORONARY ARTERY DISEASE', 'STEMI', 'MI CHF', 'BRADYCARDIA', 'VF ARREST', 'PERICARDIAL EFFUSION', 'PULMONARY EDEMA, MI', 'PULMONARY EDEMA\\\\CATH', 'CRITICAL AORTIC STENOSIS/HYPOTENSION', 'INFERIOR MYOCARDIAL INFARCTION\\\\CATH'],\n",
    "    'Respiratory': ['ACUTE RESPIRATORY DISTRESS SYNDROME', 'ASTHMA', 'COPD FLARE', 'PNEUMONIA', 'RESPIRATORY DISTRESS', 'SHORTNESS OF BREATH', 'HYPOXIA', 'TACHYPNEA', 'PLEURAL EFFUSION', 'MEDIASTINAL ADENOPATHY'],\n",
    "    'Neurological': ['ALTERED MENTAL STATUS', 'SEIZURE', 'STATUS EPILEPTICUS', 'STROKE/TIA', 'INTRACRANIAL HEMORRHAGE', 'HEADACHE', 'FACIAL NUMBNESS', 'BASAL GANGLIN BLEED', 'ALTERED MENTAL STATUS'],\n",
    "    'Infectious': ['CELLULITIS', 'FEVER', 'SEPSIS', 'URINARY TRACT INFECTION', 'UROSEPSIS', 'PYELONEPHRITIS', 'UTI', 'HIV', 'ABSCESS', 'PNEUMONIA;TELEMETRY', 'SEPSIS; UTI', 'FEVER;URINARY TRACT INFECTION'],\n",
    "    'Gastrointestinal': ['ABDOMINAL PAIN', 'GASTROINTESTINAL BLEED', 'LOWER GI BLEED', 'UPPER GI BLEED', 'VARICEAL BLEED', 'HEPATITIS', 'LIVER FAILURE', 'CHOLECYSTITIS', 'CHOLANGITIS', 'PANCREATITIS', 'ACUTE CHOLECYSTITIS', 'ACUTE CHOLANGITIS', 'HEPATITIS B', 'ALCOHOLIC HEPATITIS', 'ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'FAILURE TO THRIVE'],\n",
    "    'Renal': ['ACUTE RENAL FAILURE', 'CHRONIC KIDNEY DISEASE', 'RENAL CANCER', 'HYPOTENSION, RENAL FAILURE'],\n",
    "    'Endocrine': ['DIABETES', 'HYPOGLYCEMIA', 'HYPERGLYCEMIA', 'HYPONATREMIA'],\n",
    "    'Oncology': ['LUNG CANCER', 'BREAST CANCER', 'COLON CANCER', 'LEUKEMIA', 'LYMPHOMA', 'METASTATIC MELANOMA', 'NON SMALL CELL CANCER', 'METASTIC MELANOMA;ANEMIA', 'CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION'],\n",
    "    'Trauma': ['FRACTURE', 'MOTOR VEHICLE ACCIDENT', 'SUBDURAL HEMATOMA', 'LEFT HIP FRACTURE', 'RIGHT HUMEROUS FRACTURE', 'HUMERAL FRACTURE', 'S/P MOTOR VEHICLE ACCIDENT', 'ACUTE SUBDURAL HEMATOMA'],\n",
    "    'Other': ['OVERDOSE', 'FAILURE TO THRIVE', 'MEDIASTINAL ADENOPATHY', 'ARREST', 'OVERDOSE', 'AROMEGLEY;BURKITTS LYMPHOMA', 'TRACHEAL ESOPHAGEAL FISTULA', 'TRACHEAL STENOSIS', 'VOLVULUS', 'ANEMIA', 'BURKITTS LYMPHOMA', 'NON SMALL CELL CANCER;HYPOXIA', 'METASTATIC MELANOMA;BRAIN METASTASIS']\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to map each disease column to its disease type(s)\n",
    "disease_to_type = {}\n",
    "\n",
    "# Process each disease column\n",
    "for col in disease_columns:\n",
    "    # Split disease names if they contain multiple diseases\n",
    "    diseases = re.split(';|,|/', col)\n",
    "    diseases = [disease.strip().upper() for disease in diseases]\n",
    "    types = set()\n",
    "    for disease in diseases:\n",
    "        # Find the disease type for this disease\n",
    "        found = False\n",
    "        for disease_type, disease_list in disease_type_mapping.items():\n",
    "            if disease in disease_list:\n",
    "                types.add(disease_type)\n",
    "                found = True\n",
    "        if not found:\n",
    "            types.add('Other')  # Assign 'Other' if disease not found in mapping\n",
    "    disease_to_type[col] = types\n",
    "\n",
    "# Step 3: For each disease type, sum the corresponding disease columns\n",
    "for disease_type in disease_type_mapping.keys():\n",
    "    # Get all columns that map to this disease type\n",
    "    cols = [col for col, types in disease_to_type.items() if disease_type in types]\n",
    "    if cols:\n",
    "        # Sum the columns (since they are binary, this counts the number of diseases)\n",
    "        df[disease_type] = df[cols].sum(axis=1)\n",
    "    else:\n",
    "        df[disease_type] = 0  # If no diseases of this type are present\n",
    "\n",
    "# Step 4: Optionally, drop the individual disease columns\n",
    "df.drop(columns=disease_columns, inplace=True)\n",
    "\n",
    "df.to_csv('improving2.csv', index=False)\n",
    "\n",
    "# Now, df contains the non-disease columns and the summed disease type columns\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Melhores Variaveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Update the classifier in the pipeline to Gradient Boosting\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define parameter grid for Gradient Boosting tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [3, 5, 10],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(model_pipeline, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Load the model later\n",
    "loaded_model = joblib.load('antibiotic_resistance_model.pkl')\n",
    "\n",
    "'''\n",
    "# Assuming new_data is a DataFrame with the same structure as your original X\n",
    "new_predictions = loaded_model.predict(new_data)\n",
    "\n",
    "# View the predictions\n",
    "print(new_predictions)\n",
    "'''\n",
    "X_train.columns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
